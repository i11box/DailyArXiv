---
title: Latest 6 Papers - March 17, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Accelerate Diffusion Models
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[GoT: Unleashing Reasoning Capability of Multimodal Large Language Model for Visual Generation and Editing](http://arxiv.org/abs/2503.10639v1)** | 2025-03-13 | <details><summary>Datas...</summary><p>Dataset and models are released in https://github.com/rongyaofang/GoT</p></details> |
| **[Distilling Diversity and Control in Diffusion Models](http://arxiv.org/abs/2503.10637v1)** | 2025-03-13 | <details><summary>Proje...</summary><p>Project Page: https://distillation.baulab.info</p></details> |
| **[V2Edit: Versatile Video Diffusion Editor for Videos and 3D Scenes](http://arxiv.org/abs/2503.10634v1)** | 2025-03-13 | <details><summary>Proje...</summary><p>Project Website: https://immortalco.github.io/V2Edit/</p></details> |
| **[A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1](http://arxiv.org/abs/2503.10635v1)** | 2025-03-13 | <details><summary>Code ...</summary><p>Code at: https://github.com/VILA-Lab/M-Attack</p></details> |
| **[UniGoal: Towards Universal Zero-shot Goal-oriented Navigation](http://arxiv.org/abs/2503.10630v1)** | 2025-03-13 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025</p></details> |
| **[SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems](http://arxiv.org/abs/2503.10627v1)** | 2025-03-13 | <details><summary>Initi...</summary><p>Initially released in September 2024. Project page: https://sciverse-cuhk.github.io</p></details> |

## Vision Transformer Compression
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[GoT: Unleashing Reasoning Capability of Multimodal Large Language Model for Visual Generation and Editing](http://arxiv.org/abs/2503.10639v1)** | 2025-03-13 | <details><summary>Datas...</summary><p>Dataset and models are released in https://github.com/rongyaofang/GoT</p></details> |
| **[A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1](http://arxiv.org/abs/2503.10635v1)** | 2025-03-13 | <details><summary>Code ...</summary><p>Code at: https://github.com/VILA-Lab/M-Attack</p></details> |
| **[Kolmogorov-Arnold Attention: Is Learnable Attention Better For Vision Transformers?](http://arxiv.org/abs/2503.10632v1)** | 2025-03-13 | <details><summary>Prepr...</summary><p>Preprint, Appendix included</p></details> |
| **[SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems](http://arxiv.org/abs/2503.10627v1)** | 2025-03-13 | <details><summary>Initi...</summary><p>Initially released in September 2024. Project page: https://sciverse-cuhk.github.io</p></details> |
| **[LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds](http://arxiv.org/abs/2503.10625v1)** | 2025-03-13 | <details><summary>Proje...</summary><p>Project Page: https://lingtengqiu.github.io/LHM/</p></details> |
| **[Transformers without Normalization](http://arxiv.org/abs/2503.10622v1)** | 2025-03-13 | <details><summary>CVPR ...</summary><p>CVPR 2025; Project page: https://jiachenzhu.github.io/DyT/</p></details> |

## fast inference
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[The Curse of Conditions: Analyzing and Improving Optimal Transport for Conditional Flow-Based Generation](http://arxiv.org/abs/2503.10636v1)** | 2025-03-13 | <details><summary>Proje...</summary><p>Project page: https://hkchengrex.github.io/C2OT</p></details> |
| **[Distilling Diversity and Control in Diffusion Models](http://arxiv.org/abs/2503.10637v1)** | 2025-03-13 | <details><summary>Proje...</summary><p>Project Page: https://distillation.baulab.info</p></details> |
| **[UniGoal: Towards Universal Zero-shot Goal-oriented Navigation](http://arxiv.org/abs/2503.10630v1)** | 2025-03-13 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025</p></details> |
| **[LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds](http://arxiv.org/abs/2503.10625v1)** | 2025-03-13 | <details><summary>Proje...</summary><p>Project Page: https://lingtengqiu.github.io/LHM/</p></details> |
| **[DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model for Driving Scenario Understanding](http://arxiv.org/abs/2503.10621v1)** | 2025-03-13 | <details><summary>8 pag...</summary><p>8 pages, 4 figures, 3 tables, github: https://github.com/ayesha-ishaq/DriveLMM-o1</p></details> |
| **[OVTR: End-to-End Open-Vocabulary Multiple Object Tracking with Transformer](http://arxiv.org/abs/2503.10616v1)** | 2025-03-13 | <details><summary>Accep...</summary><p>Accepted by ICLR 2025</p></details> |


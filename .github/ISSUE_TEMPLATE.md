---
title: Latest 6 Papers - March 19, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Accelerate Diffusion Models
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MetaScale: Test-Time Scaling with Evolving Meta-Thoughts](http://arxiv.org/abs/2503.13447v1)** | 2025-03-17 | Work in progress |
| **[MoManipVLA: Transferring Vision-language-action Models for General Mobile Manipulation](http://arxiv.org/abs/2503.13446v1)** | 2025-03-17 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025. Project Page: https://gary3410.github.io/momanipVLA/</p></details> |
| **[Faithfulness of LLM Self-Explanations for Commonsense Tasks: Larger Is Better, and Instruction-Tuning Allows Trade-Offs but Not Pareto Dominance](http://arxiv.org/abs/2503.13445v1)** | 2025-03-17 | 38 pages, 9 figures |
| **[VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning](http://arxiv.org/abs/2503.13444v1)** | 2025-03-17 | <details><summary>Proje...</summary><p>Project Page: https://videomind.github.io/</p></details> |
| **[DPC: Dual-Prompt Collaboration for Tuning Vision-Language Models](http://arxiv.org/abs/2503.13443v1)** | 2025-03-17 | <details><summary>Accep...</summary><p>Accepted by the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2025 (CVPR 2025)</p></details> |
| **[Humanoid Policy ~ Human Policy](http://arxiv.org/abs/2503.13441v1)** | 2025-03-17 | <details><summary>Code ...</summary><p>Code and data: https://human-as-robot.github.io/</p></details> |

## Vision Transformer Compression
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MoManipVLA: Transferring Vision-language-action Models for General Mobile Manipulation](http://arxiv.org/abs/2503.13446v1)** | 2025-03-17 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025. Project Page: https://gary3410.github.io/momanipVLA/</p></details> |
| **[DPC: Dual-Prompt Collaboration for Tuning Vision-Language Models](http://arxiv.org/abs/2503.13443v1)** | 2025-03-17 | <details><summary>Accep...</summary><p>Accepted by the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2025 (CVPR 2025)</p></details> |
| **[Humanoid Policy ~ Human Policy](http://arxiv.org/abs/2503.13441v1)** | 2025-03-17 | <details><summary>Code ...</summary><p>Code and data: https://human-as-robot.github.io/</p></details> |
| **[MaTVLM: Hybrid Mamba-Transformer for Efficient Vision-Language Modeling](http://arxiv.org/abs/2503.13440v1)** | 2025-03-17 | <details><summary>Code ...</summary><p>Code and model are available at http://github.com/hustvl/MaTVLM</p></details> |
| **[xLSTM 7B: A Recurrent LLM for Fast and Efficient Inference](http://arxiv.org/abs/2503.13427v1)** | 2025-03-17 | <details><summary>Code ...</summary><p>Code available at: https://github.com/NX-AI/xlstm and https://github.com/NX-AI/xlstm-jax</p></details> |
| **[SuperBPE: Space Travel for Language Models](http://arxiv.org/abs/2503.13423v1)** | 2025-03-17 | <details><summary>prepr...</summary><p>preprint, code and artifacts will become available at https://superbpe.github.io/</p></details> |

## fast inference
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MetaScale: Test-Time Scaling with Evolving Meta-Thoughts](http://arxiv.org/abs/2503.13447v1)** | 2025-03-17 | Work in progress |
| **[MaTVLM: Hybrid Mamba-Transformer for Efficient Vision-Language Modeling](http://arxiv.org/abs/2503.13440v1)** | 2025-03-17 | <details><summary>Code ...</summary><p>Code and model are available at http://github.com/hustvl/MaTVLM</p></details> |
| **[xLSTM 7B: A Recurrent LLM for Fast and Efficient Inference](http://arxiv.org/abs/2503.13427v1)** | 2025-03-17 | <details><summary>Code ...</summary><p>Code available at: https://github.com/NX-AI/xlstm and https://github.com/NX-AI/xlstm-jax</p></details> |
| **[SuperBPE: Space Travel for Language Models](http://arxiv.org/abs/2503.13423v1)** | 2025-03-17 | <details><summary>prepr...</summary><p>preprint, code and artifacts will become available at https://superbpe.github.io/</p></details> |
| **[TimeZero: Temporal Video Grounding with Reasoning-Guided LVLM](http://arxiv.org/abs/2503.13377v1)** | 2025-03-17 | <details><summary>Code:...</summary><p>Code: https://github.com/www-Ye/TimeZero</p></details> |
| **[Sightation Counts: Leveraging Sighted User Feedback in Building a BLV-aligned Dataset of Diagram Descriptions](http://arxiv.org/abs/2503.13369v1)** | 2025-03-17 | <details><summary>37 pa...</summary><p>37 pages, 10 figures, 21 tables</p></details> |


---
title: Latest 6 Papers - October 03, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Efficient Diffusion Models
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Prompt Tuning Decision Transformers with Structured and Scalable Bandits](http://arxiv.org/abs/2502.04979v3)** | 2025-10-01 | <details><summary>Accep...</summary><p>Accepted at NeurIPS 2025</p></details> |

## Transformer Compression
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Prompt Tuning Decision Transformers with Structured and Scalable Bandits](http://arxiv.org/abs/2502.04979v3)** | 2025-10-01 | <details><summary>Accep...</summary><p>Accepted at NeurIPS 2025</p></details> |
| **[Unpacking Let Alone: Human-Scale Models Generalize to a Rare Construction in Form but not Meaning](http://arxiv.org/abs/2506.04408v2)** | 2025-10-01 | <details><summary>Empir...</summary><p>Empirical Methods for Natural Language Processing (EMNLP) 2025, Camera-Ready Version</p></details> |
| **[REAL: Reading Out Transformer Activations for Precise Localization in Language Model Steering](http://arxiv.org/abs/2506.08359v2)** | 2025-10-01 | Preprint |
| **[Estimating Visceral Adiposity from Wrist-Worn Accelerometry](http://arxiv.org/abs/2506.09167v2)** | 2025-10-01 | <details><summary>This ...</summary><p>This article has been accepted for publication in IEEE Journal of Biomedical and Health Informatics</p></details> |
| **[SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration](http://arxiv.org/abs/2410.02367v9)** | 2025-10-01 | <details><summary>@inpr...</summary><p>@inproceedings{zhang2025sageattention, title={SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration}, author={Zhang, Jintao and Wei, Jia and Zhang, Pengle and Zhu, Jun and Chen, Jianfei}, booktitle={International Conference on Learning Representations (ICLR)}, year={2025} }</p></details> |
| **[CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification](http://arxiv.org/abs/2508.21046v2)** | 2025-10-01 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025, Project Page: https://jiutian-vl.github.io/CogVLA-page</p></details> |

## Fast Inference
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Prompt Tuning Decision Transformers with Structured and Scalable Bandits](http://arxiv.org/abs/2502.04979v3)** | 2025-10-01 | <details><summary>Accep...</summary><p>Accepted at NeurIPS 2025</p></details> |
| **[Ultra-Fast Language Generation via Discrete Diffusion Divergence Instruct](http://arxiv.org/abs/2509.25035v2)** | 2025-10-01 | <details><summary>56 pa...</summary><p>56 pages, 7 figures, 7 tables</p></details> |
| **[REAL: Reading Out Transformer Activations for Precise Localization in Language Model Steering](http://arxiv.org/abs/2506.08359v2)** | 2025-10-01 | Preprint |
| **[Estimating Visceral Adiposity from Wrist-Worn Accelerometry](http://arxiv.org/abs/2506.09167v2)** | 2025-10-01 | <details><summary>This ...</summary><p>This article has been accepted for publication in IEEE Journal of Biomedical and Health Informatics</p></details> |
| **[SpargeAttention: Accurate and Training-free Sparse Attention Accelerating Any Model Inference](http://arxiv.org/abs/2502.18137v7)** | 2025-10-01 | <details><summary>@inpr...</summary><p>@inproceedings{zhang2025spargeattn, title={Spargeattn: Accurate sparse attention accelerating any model inference}, author={Zhang, Jintao and Xiang, Chendong and Huang, Haofeng and Wei, Jia and Xi, Haocheng and Zhu, Jun and Chen, Jianfei}, booktitle={International Conference on Machine Learning (ICML)}, year={2025} }</p></details> |
| **[On Causal Inference for the Survivor Function](http://arxiv.org/abs/2507.16691v3)** | 2025-10-01 | <details><summary>arXiv...</summary><p>arXiv admin note: substantial text overlap with arXiv:2306.16571</p></details> |


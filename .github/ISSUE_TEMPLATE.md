---
title: Latest 6 Papers - October 16, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Efficient Diffusion Models
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Detect Anything via Next Point Prediction](http://arxiv.org/abs/2510.12798v1)** | 2025-10-14 | <details><summary>homep...</summary><p>homepage: https://rex-omni.github.io/</p></details> |
| **[UniFusion: Vision-Language Model as Unified Encoder in Image Generation](http://arxiv.org/abs/2510.12789v1)** | 2025-10-14 | <details><summary>Proje...</summary><p>Project page at https://thekevinli.github.io/unifusion/</p></details> |
| **[Efficient Real-World Deblurring using Single Images: AIM 2025 Challenge Report](http://arxiv.org/abs/2510.12788v1)** | 2025-10-14 | <details><summary>ICCV ...</summary><p>ICCV 2025 - AIM Workshop</p></details> |
| **[MVP4D: Multi-View Portrait Video Diffusion for Animatable 4D Avatars](http://arxiv.org/abs/2510.12785v1)** | 2025-10-14 | 18 pages, 12 figures |
| **[SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models](http://arxiv.org/abs/2510.12784v1)** | 2025-10-14 | <details><summary>20 pa...</summary><p>20 pages, 8 figures, webpage can be seen in https://waynejin0918.github.io/srum_web/</p></details> |
| **[What If : Understanding Motion Through Sparse Interactions](http://arxiv.org/abs/2510.12777v1)** | 2025-10-14 | <details><summary>Proje...</summary><p>Project page and code: https://compvis.github.io/flow-poke-transformer</p></details> |

## Transformer Compression
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations](http://arxiv.org/abs/2510.12795v1)** | 2025-10-14 | Appears at ICCV 2025 |
| **[UniFusion: Vision-Language Model as Unified Encoder in Image Generation](http://arxiv.org/abs/2510.12789v1)** | 2025-10-14 | <details><summary>Proje...</summary><p>Project page at https://thekevinli.github.io/unifusion/</p></details> |
| **[What If : Understanding Motion Through Sparse Interactions](http://arxiv.org/abs/2510.12777v1)** | 2025-10-14 | <details><summary>Proje...</summary><p>Project page and code: https://compvis.github.io/flow-poke-transformer</p></details> |
| **[Dr.LLM: Dynamic Layer Routing in LLMs](http://arxiv.org/abs/2510.12773v1)** | 2025-10-14 | <details><summary>17 pa...</summary><p>17 pages, Under submission</p></details> |
| **[SPORTS: Simultaneous Panoptic Odometry, Rendering, Tracking and Segmentation for Urban Scenes Understanding](http://arxiv.org/abs/2510.12749v1)** | 2025-10-14 | <details><summary>Accep...</summary><p>Accepted by IEEE Transactions on Multimedia</p></details> |
| **[DarkIR: Robust Low-Light Image Restoration](http://arxiv.org/abs/2412.13443v3)** | 2025-10-14 | CVPR 2025 |

## Fast Inference
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[UniFusion: Vision-Language Model as Unified Encoder in Image Generation](http://arxiv.org/abs/2510.12789v1)** | 2025-10-14 | <details><summary>Proje...</summary><p>Project page at https://thekevinli.github.io/unifusion/</p></details> |
| **[Dr.LLM: Dynamic Layer Routing in LLMs](http://arxiv.org/abs/2510.12773v1)** | 2025-10-14 | <details><summary>17 pa...</summary><p>17 pages, Under submission</p></details> |
| **[AnyUp: Universal Feature Upsampling](http://arxiv.org/abs/2510.12764v1)** | 2025-10-14 | <details><summary>Proje...</summary><p>Project Website: https://wimmerth.github.io/anyup/</p></details> |
| **[KonfAI: A Modular and Fully Configurable Framework for Deep Learning in Medical Imaging](http://arxiv.org/abs/2508.09823v2)** | 2025-10-14 | <details><summary>https...</summary><p>https://github.com/vboussot/KonfAI</p></details> |
| **[Multi-View Graph Learning with Graph-Tuple](http://arxiv.org/abs/2510.10341v2)** | 2025-10-14 | <details><summary>Submi...</summary><p>Submitted to TAG workshop</p></details> |
| **[T(R,O) Grasp: Efficient Graph Diffusion of Robot-Object Spatial Transformation for Cross-Embodiment Dexterous Grasping](http://arxiv.org/abs/2510.12724v1)** | 2025-10-14 | 12 pages, 14 figures |


---
title: Latest 6 Papers - May 29, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Efficient Diffusion Models
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Vision Transformers with Self-Distilled Registers](http://arxiv.org/abs/2505.21501v1)** | 2025-05-27 | 27 pages, 14 figures |
| **[ViewSpatial-Bench: Evaluating Multi-perspective Spatial Localization in Vision-Language Models](http://arxiv.org/abs/2505.21500v1)** | 2025-05-27 | <details><summary>Proje...</summary><p>Project: https://zju-real.github.io/ViewSpatial-Page/</p></details> |
| **[Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers](http://arxiv.org/abs/2505.21497v1)** | 2025-05-27 | <details><summary>Proje...</summary><p>Project Page: https://github.com/Paper2Poster/Paper2Poster</p></details> |
| **[UI-Genie: A Self-Improving Approach for Iteratively Boosting MLLM-based Mobile GUI Agents](http://arxiv.org/abs/2505.21496v1)** | 2025-05-27 | <details><summary>https...</summary><p>https://github.com/Euphoria16/UI-Genie</p></details> |
| **[Be Decisive: Noise-Induced Layouts for Multi-Subject Generation](http://arxiv.org/abs/2505.21488v1)** | 2025-05-27 | <details><summary>SIGGR...</summary><p>SIGGRAPH 2025. Project page: https://omer11a.github.io/be-decisive/</p></details> |
| **[Hardware-Efficient Attention for Fast Decoding](http://arxiv.org/abs/2505.21487v1)** | 2025-05-27 | <details><summary>37 pa...</summary><p>37 pages, 15 figures, 45 tables</p></details> |

## Transformer Compression
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Vision Transformers with Self-Distilled Registers](http://arxiv.org/abs/2505.21501v1)** | 2025-05-27 | 27 pages, 14 figures |
| **[Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers](http://arxiv.org/abs/2505.21497v1)** | 2025-05-27 | <details><summary>Proje...</summary><p>Project Page: https://github.com/Paper2Poster/Paper2Poster</p></details> |
| **[OmniSync: Towards Universal Lip Synchronization via Diffusion Transformers](http://arxiv.org/abs/2505.21448v1)** | 2025-05-27 | <details><summary>https...</summary><p>https://ziqiaopeng.github.io/OmniSync/</p></details> |
| **[Cryptography from Lossy Reductions: Towards OWFs from ETH, and Beyond](http://arxiv.org/abs/2505.21442v1)** | 2025-05-27 | 56 pages |
| **[Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs](http://arxiv.org/abs/2407.01082v6)** | 2025-05-27 | <details><summary>Oral ...</summary><p>Oral presentation at ICLR 2025. Camera-ready version available at https://iclr.cc/virtual/2025/poster/30358</p></details> |
| **[Autoencoding Random Forests](http://arxiv.org/abs/2505.21441v1)** | 2025-05-27 | <details><summary>10 pa...</summary><p>10 pages main text, 25 pages total. 5 figures main text, 9 figures total</p></details> |

## Fast Inference
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Hardware-Efficient Attention for Fast Decoding](http://arxiv.org/abs/2505.21487v1)** | 2025-05-27 | <details><summary>37 pa...</summary><p>37 pages, 15 figures, 45 tables</p></details> |
| **[Annealing Flow Generative Models Towards Sampling High-Dimensional and Multi-Modal Distributions](http://arxiv.org/abs/2409.20547v4)** | 2025-05-27 | <details><summary>This ...</summary><p>This paper has been accepted to ICML 2025 and will appear in the Proceedings of Machine Learning Research (PMLR)</p></details> |
| **[Scaling External Knowledge Input Beyond Context Windows of LLMs via Multi-Agent Collaboration](http://arxiv.org/abs/2505.21471v1)** | 2025-05-27 | <details><summary>30 pa...</summary><p>30 pages, 9 figures. Code and data are available at https://github.com/THUNLP-MT/ExtAgents</p></details> |
| **[OmniSync: Towards Universal Lip Synchronization via Diffusion Transformers](http://arxiv.org/abs/2505.21448v1)** | 2025-05-27 | <details><summary>https...</summary><p>https://ziqiaopeng.github.io/OmniSync/</p></details> |
| **[Can Large Reasoning Models Self-Train?](http://arxiv.org/abs/2505.21444v1)** | 2025-05-27 | <details><summary>Proje...</summary><p>Project website: https://self-rewarding-llm-training.github.io/</p></details> |
| **[DecisionFlow: Advancing Large Language Model as Principled Decision Maker](http://arxiv.org/abs/2505.21397v1)** | 2025-05-27 | 24 pages, 13 figures |


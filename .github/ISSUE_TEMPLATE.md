---
title: Latest 6 Papers - March 03, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Training-free Acceleration
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ACCORD: Application Context-aware Cross-layer Optimization and Resource Design for 5G/NextG Machine-centric Applications](http://arxiv.org/abs/2502.20320v1)** | 2025-02-27 | <details><summary>Accep...</summary><p>Accepted for publications at ICC 2025</p></details> |
| **[Attention Distillation: A Unified Approach to Visual Characteristics Transfer](http://arxiv.org/abs/2502.20235v1)** | 2025-02-27 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025. Project page: https://github.com/xugao97/AttentionDistillation</p></details> |
| **[Preconditioned Score-based Generative Models](http://arxiv.org/abs/2302.06504v3)** | 2025-02-27 | IJCV 2025 |
| **[AgentSquare: Automatic LLM Agent Search in Modular Design Space](http://arxiv.org/abs/2410.06153v3)** | 2025-02-27 | 25 pages |
| **[A Novel P-bit-based Probabilistic Computing Approach for Solving the 3-D Protein Folding Problem](http://arxiv.org/abs/2502.20050v1)** | 2025-02-27 | 14pages, 6 fingures |
| **[Large-Scale Simulations of Fully Resolved Complex Moving Geometries with Partially Saturated Cells](http://arxiv.org/abs/2502.20049v1)** | 2025-02-27 | 13 pages, 16 figures |

## DiT
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[3DIS-FLUX: simple and efficient multi-instance generation with DiT rendering](http://arxiv.org/abs/2501.05131v1)** | 2025-01-09 | tech report |
| **[Unveiling Redundancy in Diffusion Transformers (DiTs): A Systematic Study](http://arxiv.org/abs/2411.13588v1)** | 2024-11-18 | <details><summary>9 pag...</summary><p>9 pages including reference</p></details> |
| **[On Statistical Rates and Provably Efficient Criteria of Latent Diffusion Transformers (DiTs)](http://arxiv.org/abs/2407.01079v3)** | 2024-10-31 | <details><summary>Accep...</summary><p>Accepted at NeurIPS 2024. v3 updated to camera-ready version with many typos fixed; v2 fixed typos, added Fig. 1 and added clarifications</p></details> |
| **[Lumina-Next: Making Lumina-T2X Stronger and Faster with Next-DiT](http://arxiv.org/abs/2406.18583v1)** | 2024-06-05 | <details><summary>Code ...</summary><p>Code at: https://github.com/Alpha-VLLM/Lumina-T2X</p></details> |
| **[DiT: Self-supervised Pre-training for Document Image Transformer](http://arxiv.org/abs/2203.02378v3)** | 2022-07-19 | ACM Multimedia 2022 |

## Attention Optimization
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Beyond Next-Token: Next-X Prediction for Autoregressive Visual Generation](http://arxiv.org/abs/2502.20388v1)** | 2025-02-27 | <details><summary>Proje...</summary><p>Project page at \url{https://oliverrensu.github.io/project/xAR}</p></details> |
| **[Multi-Turn Code Generation Through Single-Step Rewards](http://arxiv.org/abs/2502.20380v1)** | 2025-02-27 | <details><summary>9 pag...</summary><p>9 pages (not including references or appendix); 6 figures (in main paper); (v1) preprint</p></details> |
| **[Multi-Agent Path Planning in Complex Environments using Gaussian Belief Propagation with Global Path Finding](http://arxiv.org/abs/2502.20369v1)** | 2025-02-27 | <details><summary>Accep...</summary><p>Accepted by "International Conference on Robotics and Automation" - ICRA 2025</p></details> |
| **[Removing Neural Signal Artifacts with Autoencoder-Targeted Adversarial Transformers (AT-AT)](http://arxiv.org/abs/2502.05332v2)** | 2025-02-27 | <details><summary>Accep...</summary><p>Accepted at CNS 2025, Boston, MA, USA</p></details> |
| **[Trajectory-to-Action Pipeline (TAP): Automated Scenario Description Extraction for Autonomous Vehicle Behavior Comparison](http://arxiv.org/abs/2502.20353v1)** | 2025-02-27 | 8 pages, 6 figures |
| **[Geometric Machine Learning on EEG Signals](http://arxiv.org/abs/2502.05334v2)** | 2025-02-27 | <details><summary>Accep...</summary><p>Accepted in Proceedings of Machine Learning Research (PMLR), 2025</p></details> |

